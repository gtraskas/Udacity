{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation\n",
    "\n",
    "### Your First (Overfit) POI Identifier\n",
    "You’ll start by building the simplest imaginable (unvalidated) POI identifier. The starter code (validation/validate_poi.py) for this lesson is pretty bare--all it does is read in the data, and format it into lists of labels and features. Create a decision tree classifier (just use the default parameters), train it on all the data (you will fix this in the next part!), and print out the accuracy. THIS IS AN OVERFIT TREE, DO NOT TRUST THIS NUMBER! Nonetheless, what’s the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Starter code for the validation mini-project.\n",
    "    The first step toward building your POI identifier!\n",
    "    Start by loading/formatting the data\n",
    "    After that, it's not our code anymore--it's yours!\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "data_dict = pickle.load(open(\"final_project_dataset.pkl\", \"rb\") )\n",
    "\n",
    "### first element is our labels, any added elements are predictor\n",
    "### features. Keep this the same for the mini-project, but you'll\n",
    "### have a different feature list when you do the final project.\n",
    "features_list = [\"poi\", \"salary\"]\n",
    "\n",
    "data = featureFormat(data_dict, features_list, sort_keys = 'python2_lesson13_keys.pkl')\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "### it's all yours from here forward!  \n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "# Create classifier\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Fit the classifier on the training features and labels\n",
    "clf.fit(features, labels)\n",
    "\n",
    "# Make prediction - Store predictions in a list named pred\n",
    "pred = clf.predict(features)\n",
    "\n",
    "# Calculate the accuracy on the test data\n",
    "print(clf.score(features, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying a Training/Testing Regime\n",
    "Now you’ll add in training and testing, so that you get a trustworthy accuracy number. Use the train_test_split validation available in sklearn.cross_validation; hold out 30% of the data for testing and set the random_state parameter to 42 (random_state controls which points go into the training set and which are used for testing; setting it to 42 means we know exactly which events are in which set, and can check the results you get). What’s your updated accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create classifier\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Fit the classifier on the training features and labels\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "# Make prediction - Store predictions in a list named pred\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "# Calculate the accuracy on the test data\n",
    "print(clf.score(features_test, labels_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
