{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull Data out of HTML and XML files\n",
    "An example to show how to extract data from the [AirTrans website](https://www.transtats.bts.gov/Data_Elements.aspx?Data=2) using the python library BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries.\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "fname = 'virgin_and_logan_airport.html'\n",
    "\n",
    "# Create a function which finds the id codes of the Carriers and Airports and make a list of them.\n",
    "def options(soup, id):\n",
    "    option_values = []\n",
    "    code_list = soup.find(id=id)\n",
    "    for option in code_list.find_all('option'):\n",
    "        # Extract the Carriers list excluding all the combination values such as AllUS.\n",
    "        if 'All' not in option['value']: # All is inside AllUS and AllForeign too.\n",
    "            option_values.append(option['value'])\n",
    "    return option_values\n",
    "\n",
    "# Create a function which prints the Carriers and Airports codes.\n",
    "def print_list(label, codes):\n",
    "    print('\\n%s:' % label)\n",
    "    for c in codes:\n",
    "        print(c)\n",
    "\n",
    "# Create a function which opens the downloaded local html file, gets the codes and prints them out.\n",
    "def main():\n",
    "    soup = BeautifulSoup(open(fname, encoding=\"utf8\"), 'lxml')\n",
    "    codes = options(soup, 'CarrierList')\n",
    "    print_list('Carriers', codes)\n",
    "    codes = options(soup, 'AirportList')\n",
    "    print_list('Airports', codes)\n",
    "\n",
    "# Call the function to find the Carrier and Airport codes.\n",
    "if False:\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a persistent session. Persist cookies across requests.\n",
    "s = requests.Session()\n",
    "\n",
    "# Get the webpage.\n",
    "r = s.get('https://www.transtats.bts.gov/Data_Elements.aspx?Data=2')\n",
    "\n",
    "# Parse the webpage using the BeautifulSoup library.\n",
    "soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "# Find the required values getting help from the web browser's developer tools (inspect element).\n",
    "viewstate_element = soup.find(id='__VIEWSTATE')\n",
    "viewstate = viewstate_element['value']\n",
    "eventvalidation_element = soup.find(id='__EVENTVALIDATION')\n",
    "eventvalidation = eventvalidation_element['value']\n",
    "viewstategenerator_element = soup.find(id='__VIEWSTATEGENERATOR')\n",
    "viewstategenerator = viewstategenerator_element['value']\n",
    "\n",
    "# Make an HTTP POST request (Submit data to be processed to a specified resource).\n",
    "# Get sample codes from the previous generated list.\n",
    "r = s.post(\"https://www.transtats.bts.gov/Data_Elements.aspx?Data=2\",\n",
    "           data = (\n",
    "                   (\"__EVENTTARGET\", \"\"),\n",
    "                   (\"__EVENTARGUMENT\", \"\"),\n",
    "                   (\"__VIEWSTATE\", viewstate),\n",
    "                   (\"__VIEWSTATEGENERATOR\",viewstategenerator),\n",
    "                   (\"__EVENTVALIDATION\", eventvalidation),\n",
    "                   (\"CarrierList\", \"VX\"),\n",
    "                   (\"AirportList\", \"BOS\"),\n",
    "                   (\"Submit\", \"Submit\")\n",
    "                   ))\n",
    "\n",
    "# Open again the local html file with write mode which is used to edit and write new information to the file.\n",
    "# Get the body of the response decoded to unicode text and write it to the file.\n",
    "def export_to_file():\n",
    "    outfile = open('{0}-{1}.html'.format('VX', 'BOS'), 'w')\n",
    "    with open(fname, 'r') as f:\n",
    "        outfile.write(r.text)\n",
    "    return outfile\n",
    "\n",
    "export_to_file()\n",
    "    \n",
    "# Rename file.\n",
    "# new_fname = 'VX-BOS.html'\n",
    "# os.rename(fname, new_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract and process the flight data from the local file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filename):\n",
    "    data = []\n",
    "    info = {}\n",
    "    info['courier'], info['airport'] = filename[:6].split('-')\n",
    "    # Create a new dictionary for each entry in the output data list.\n",
    "    # Use the info dictionary defined here.\n",
    "    # Each element in the list is a reference to the same info dictionary.\n",
    "    with open(filename, 'r') as f:\n",
    "        soup = BeautifulSoup(f,'lxml')\n",
    "        rows = soup.find_all('tr', 'dataTDRight')\n",
    "#         print(rows)\n",
    "        for row in rows:\n",
    "            tds = row.find_all('td')\n",
    "            if tds[1].text != 'TOTAL':\n",
    "                info['year'] = tds[0].text\n",
    "                info['month'] = tds[1].text\n",
    "#                 info['flights'] = {'domestic': int(tds[2].text.replace(',', '')), \n",
    "#                                    'international': int(tds[3].text.replace(',', ''))}\n",
    "                data.append(info.copy())\n",
    "        \n",
    "    return data\n",
    "\n",
    "#          # Alternative solution\n",
    "#         table = soup.find(\"table\", \"dataTDRight\")\n",
    "#         for i, tr in enumerate(table.find_all(\"tr\")[1:]) :\n",
    "#             td_list = []\n",
    "#             flights = {}\n",
    "#             for td in tr.find_all(\"td\"):\n",
    "#                 td_list.append(td.get_text())\n",
    "#                 print(td_list)\n",
    "#             if td_list[0] == \"TOTAL\" or td_list[1] == \"TOTAL\":\n",
    "#                 continue \n",
    "#             else:\n",
    "#                 info['year'] = int(td_list[0])\n",
    "#                 info['month'] = int(td_list[1])\n",
    "#                 # flights[\"domestic\"]= int(td_list[2].replace(\",\",\"\"))      \n",
    "#                 # flights[\"international\"] = int(td_list[3].replace(\",\",\"\")) \n",
    "#                 info['flights'] = flights\n",
    "#                 data.append(info.copy())\n",
    "            \n",
    "#         return data\n",
    "\n",
    "if False:\n",
    "    pprint(process_file('VX-BOS.html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a method to split xml files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outfile_generator(fname):\n",
    "    count = -1\n",
    "    while True:\n",
    "        count += 1\n",
    "        yield open('[0]-[1]'.format(fname, count), 'w')\n",
    "\n",
    "def split_file(fname):\n",
    "    # Create the pattern variable on which the file is split.\n",
    "    pattern = ''\n",
    "    \n",
    "    # Create the iterator for the filename.\n",
    "    outfile_iterator = outfile_generator(fname)\n",
    "    \n",
    "    with open(fname, 'r') as initial_file:\n",
    "        for line in initial_file:\n",
    "            # Create the new file.\n",
    "            if pattern in line:\n",
    "                outfile = next(outfile_iterator)\n",
    "            # Write the line.\n",
    "            outfile.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
